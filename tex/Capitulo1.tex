\chapter{Introduction}\label{ch_introduction}%

\section{Problem Definition}

Among the different causes that lead a system to fail, some can be tracked back to design decisions in early system development process. The systematization provided by requirements engineering has been used to improve the quality and precision of the delivered documents, models and specification. Nonetheless, many methodologies do not further investigate or verify if the system-to-be conforms to non-functional constraints based on its design model, relying only on later monitoring and testing.

% both strategically through higher level goals and operationally through lower level goals and tasks

Non-functional dependability requirements are important metrics related to the correct system operation. Dependability defines the ability of delivering a service that can justifiably be trusted. Fail forecasting should provide a qualitative and/or a quantitative evaluation of the system behaviour in respect to fault occurrence or activation, while fault removal includes the verification, diagnosis and correction~[AVIZIENIS]. For some systems, late fault correction may be very costly and, in the worse case, may happen after the manifestation of a catastrophic failure that could have been avoided early correction~[DEPENDABILITY].

In traditional Goal-oriented requirements engineering (GORE) methodologies [GORE CAC], contribution  analysis is based on domain knowledge about the positive, neutral (implicit) or negative impact of a given system alternative to one or more system goals, generally a qualitative goal. By  comparing the overall contribution of two or more alternatives, a decision is made about which one should be adopted for the system-to-be. For instance, if one goal is to communicate with a remote user mobile, alternative means for the notification agent could be to send a SMS, an internet based message or a voice call. These alternatives may contribute with different values for qualitative goals such as `reliable delivery', `fast delivery', `convenient delivery', etc. 

TROPOS contribution analysis is limited in many ways. First, it is based on domain knowledge information that may not exist or may not be precise and reliable. As a consequence, the decision of which alternative to use may be biased and lead to unexpected violations at runtime - the selected alternative may prove unable to fulfil its qualitative goals. From this, our first research question emerges:
\bigskip

\setlength{\fboxsep}{10pt}
\noindent\fbox{%
    \parbox{\textwidth}{%
        \textbf{Research Question 1}		Is it possible to improve the precision of the alternative selection in TROPOS methodology?
    }%
}\bigskip

Second, contribution analysis is limited to a static representation without any dynamic information that could be used to estimate and verify quality attributes that depend on system behaviour and its many nuances such as temporal order, cardinality and priority. From this, our second research question arises: 
\bigskip

\noindent\fbox{%
    \parbox{\textwidth}{%
        \textbf{Research Question 2}		Is it possible to complement a goal model with a behaviour specification concerning, e.g., the cardinality, temporal order and priority of the achievement of goals and the execution of tasks?
    }%
}\bigskip

Third, contribution links are deterministic. As such, the design decisions based on contribution analysis are reduced to a simple sum comparison of the concurring alternatives contributions with no support for probabilistic verification. Accordingly, our third research question is:
\bigskip

\noindent\fbox{%
    \parbox{\textwidth}{%
        \textbf{Research Question 3}		Is it possible to use a probabilistic approach for the model-based verification of non-functional requirements?
    }%
}\bigskip

Fourth, TROPOS provides no support for the estimation of non-functional metrics in temporal frames such as ``the percentage of success for a given goal in a month''. This leads us to our fourth research question:
\bigskip

\noindent\fbox{%
    \parbox{\textwidth}{%
        \textbf{Research Question 4}		Is it possible to estimate time-bounded non-functional metrics related to the achievement or failure of system goals?
    }%
}\bigskip

Additionally to the contribution analysis limitations, the context in which systems operate may not be static. Mobile and pervasive computing, among others, are examples of new computer paradigms for which the environment is dynamic. Battery, signals strength, components availability and the quality of physical resources and relevant information such as the user geographic location may vary through time, posing a new challenge to the development of socio-technical systems based on these paradigms. The contextualization of the informations gathered at RE phase becomes imperative once its validity may be threatened by changing environment conditions~[CGM]. From this, our fifth and last research question arises:
\bigskip

\noindent\fbox{%
    \parbox{\textwidth}{%
        \textbf{Research Question 5}		Is it possible to consider the context effects described by the CGM in the verification process?
    }%
}\bigskip


%for these systems must also address the problem of multiple contexts of operation.

%The contextualization of an information means that its validity is not absolute in respect to the state of the world it relates to.

\section{Proposed Solution}

Static model-based verification is a formal approach to evaluate metrics over a finite-state model representing the system behaviour. The advantage of this approach is to reduce the correction costs by anticipating failures at early stages of the development cycle using not the system itself, but its representation. As long as the system model is precise, this method may provide a reliable evaluation of non-functional metrics. 

Goal models are not restricted to strategical goals. Through decomposition, more granular goals and finally tasks are defined. Tasks are responsible for the operationalization of system goals. Thus, tasks may be directly mapped to system activities that composes the system behaviour. A model-based verification of a goal model, as it will be explained in later sections, addresses our RQ1.

%Increased analysis overhead is one of the drawbacks of this approach. Thus, its application must be well justified by the criticality level of the system and by the adoption of an appropriated verification approach. 

As the goal model proposed in TROPOS is static, no information regarding achievement/execution order, cardinality and priority of goals/tasks is available, except the activity diagram for the detailing of an agent's single capability behaviour and the sequence diagram for agents interaction. Nonetheless, this problem was tackled by Dalpiaz et al. with a regular expression language to express behaviour, e.g., how many times the same goal should be achieved and the execution order of different system tasks~[RGM]. This answers our RQ2. 

%Despite its valuable contribution to the requirements analysis and engineering, GORE still lacks the proper means to verify the conformance of some important metrics such as dependability requirements and others non-functional requirements (NFR) related to the likelihood and frequency of system execution failures. By tackling the verification of these metrics with a more precise and reliable approach, this work aims to mitigate the occurrence of failures at an early phase of the system development that must justifiably be trusted.

%In order to provide a more solid and precise approach for the non-functional verification of different system alternatives and to improve the GORE contribution analysis, we propose the extension of the TROPOS goal-oriented software development methodology with 

A probabilistic model checking (PMC) approach has already been explored and is supported by tools such as PRISM model checker[gena√≠na PMC, PRISM]. PMC is a formal method for static verification of system models. In order to verify the system-to-be defined by a goal model, a corresponding verification model should be composed of one or more combination of tasks representing alternatives whose execution must follow some behaviour specification - as proposed by Dalpiaz et al. with the runtime goal model. If individual tasks metrics are available, the goal model could be checked for properties such as reliability, availability, performance and power consumption. PMC addresses our RQ3.

PRISM is a model checker tool that supports probabilistic models and enables PCTL property verification. PCTL provides the syntax for time-bounded probabilistic properties such as ``what is the probability of failure of a given goal in the next 1 hour?''. This is useful for scenarios with restrictions affected by time, like the battery of a mobile device. The use of PCTL properties addresses both RQ3 and RQ4.

%IN PROPOSAL
%We have used the RGM proposal to fill the gap between the static goal model and its dynamic representation. This dynamic view of the goal model is translated to a probabilistic model following the PMC technique and the PRISM model checker as the tool to automate the verification. PRISM language is used to define the probabilistic model and the Probabilistic Computation Tree Logic (PCTL) to describe the properties to be verified in the model. These properties are derived from the NFR associated to corresponding system goals being verified.

Finally, to address the problem of a dynamic context of operation, the context effects over goals, means and metrics should be treated by the verification model. Context variables may be parametrized to produce a formula that can check the system and its alternatives for different contexts. The feasibility of this approach, as presented by later chapter of this work, answers RQ5. 

The probabilistic verification of NFR, performed as part of the Validation \& Verification (VV) phase in RE, should anticipate (contextual) violations of non-functional requirements. Treating a detected violation at design time may correspond to actions such as making a different choice for underlying components used by this alternative's tasks, optimizing its behaviour specification or even the disposal of this alternative as a means to satisfy its goal if there is at least one other valid alternative. PMC technique also allows the identification of system alternatives with more influence on each metric through sensitive analysis. 

%By coupling a formal verification to a goal model, our approach benefit from a clearer understanding of the system-to-be and its criticality, justifying the verification of system parts or the system whole. The automatic generation of the verification model from an extended version of the goal mode, namely the runtime goal model, greatly reduces the verification overhead. Finally, including context effects provide a more realistic representation of the system to be verified.

Runtime self-adaptation is beyond the scope of this work. However, based on the contextual analysis provided by the CGM and the enriched non-functional and dependability analysis provided by the verification of different alternatives using the PMC technique, it should not be difficult to extend the approach with the additional monitoring, planing and execution capabilities of a self-adaptation loop and have a self-adaptive architecture and mechanism reflected upon its runtime goal model requirements. These concerns should be addressed in future work.

%This space variability problem becomes more complex with the contextualization of goals, means and metrics. According to Bosh et al.[cite Bosh 2004], a high degree of variability allow the use of software in a broader range of contexts. Traditional GORE approaches are mostly used to the selection of which single alternative would exist in the system-to-be for some static context. A dynamic environment can result in contextual violations that can not be resolved just by configuration management. In these cases, a space variability may be required to keep the system properly running in different contexts.


%to a specific kind of goal called \textit{softgoal}. Softgoals are goals for which there is no clear-cut criteria. Often, they represent qualitative intentions of stakeholders, in contrast to the 

\section{Evaluation}

This proposal was evaluated with the application of the extended TROPOS methodology to the development of a Mobile Personal Emergency Response System (MPERS). This system may be seen as a body area network (BAN) with extended functionalities related to ubiquitous emergency response running in a mobile device [BAD]. Instead of static environment, the MPERS is conceived to allow patients with different health risk degrees to maintain mobility while they are monitored and assisted. If a medical emergency is detected, a geolocation feature should point out the location where the emergency response team must be addressed to. 

The MPERS features were based on real emergency response systems available at the industry and also at the BAN explored in previews work [Fernandes]. 

The evaluation process was focused in revealing the major benefits and limitations of the extended TROPOS proposal. Time to market is an important aspect for any software development methodology. Also, the soundness and precision of the proposed probabilistic verification is crucial and must be evaluated as they should not result in mislead decisions about which alternatives should be used by the system. Instead, they must anticipate any violation that could lead to a system failure, specially severe or catastrophic failures, giving analysts valuable information about where the system requirements and specification should be tailored and improved.

\section{Contributions Summary}

This section summarizes the contributions of this proposal.

%A seguir um resumo das con

\begin{enumerate}

\item A formal approach for the estimation and verification of NFR in TROPOS Goal-oriented software development methodology.
\medskip

\item Inclusion of context effects over goals, means and metrics in the probabilistic model using appropriate constructs and parameters for each case.
\medskip

\item Conversion rules between different decomposition and runtime constraints in a runtime goal model to a probabilistic model in PRISM language.
\medskip

\item A parser implementation for the regular expression (regex) language used in runtime goal models with support for execution order, cardinality, alternative execution, optional execution and conditional execution. 
\medskip

\item An automatic generation of the PRISM probabilistic model representing activities from a runtime goal model annotated with the runtime regex and graphically modelled using the TAOM4E tool that supports TROPOS methodology.

\end{enumerate}

\section{Document Organization}

This dissertation is organized as follows. Chapter~\ref{ch:baseline} presents the base concepts of this work. Chapter~\ref{ch:related_work} describe the most important related works. Chapter~\ref{ch:motivation} details the motivation for this work and the requirements for the proposed TROPOS extension. Chapter~\ref{ch:proposal} presents the proposed TROPOS extension with related TROPOS development phases for the MPERS. Chapter~\ref{ch:implementation} presents the rules for the automatic generation of a DTMC model in PRISM language from the contextual goal model with runtime regex. Chapter~\ref{ch:evaluation} evaluates the proposal and describes its benefits and limitations. Finally, Chapter~\ref{ch:conclusion} concludes this work with final considerations about the current proposal and our future work.